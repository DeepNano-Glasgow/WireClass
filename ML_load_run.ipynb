{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_loader import WireDataset\n",
    "import torch\n",
    "import math\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "from ML import Net\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "from torchmetrics.classification import F1Score, MulticlassRecall, MulticlassConfusionMatrix\n",
    "import pandas as pd\n",
    "import seaborn as sb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = WireDataset(\"Input_Data_07_25.csv\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = \"cuda\"\n",
    "else:\n",
    "    device = \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = torch.Generator().manual_seed(4)\n",
    "\n",
    "train_fraction = math.floor(len(dataset)*0.7)\n",
    "test_fraction = len(dataset) - train_fraction\n",
    "\n",
    "test_data_ind, train_data_ind = torch.utils.data.random_split(dataset, [test_fraction, train_fraction], generator = generator)\n",
    "\n",
    "dl_train = DataLoader(train_data_ind, batch_size=20, shuffle=True) #todevice\n",
    "dl_test = DataLoader(test_data_ind, batch_size=20, shuffle=True) #todevice\n",
    "\n",
    "net = Net() #todevice\n",
    "#optimizer = torch.optim.SGD(net.parameters(), lr=0.0001)\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "num_epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs_stats = np.zeros((3, 100))\n",
    "F1= F1Score(\"multiclass\", num_classes = 6)\n",
    "f1_max = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(num_epochs):  # loop over the dataset multiple times\n",
    "    epoch_loss = []\n",
    "    running_loss = 0.0\n",
    "    net.train()\n",
    "    for i, data in enumerate(dl_train, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        epoch_loss.append(loss.item())\n",
    "        if i % 10 == 9:    # print every 10 mini-batches\n",
    "            print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 10:.3f}')\n",
    "            running_loss = 0.0\n",
    "    \n",
    "    predictions_list = [] #list for predictions (predicted number of label)\n",
    "    values_list = []      #list for values (actual number of label)\n",
    "    f1_list = np.zeros(len(dl_test))\n",
    "    net.eval()\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(dl_test, 0):\n",
    "        inputs, labels = data\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        f1_list[i] = F1(outputs, labels).item()\n",
    "        if i % 10 == 9:    # print every 10 mini-batches\n",
    "            print(f\"[batch {i}, size: {dl_test.batch_size}] F1 score: {f1_list[i]}\")\n",
    "    \n",
    "    epoch_loss = np.array(epoch_loss, dtype=\"float\")\n",
    "    epochs_stats[0][epoch] = f1_list.mean()\n",
    "    epochs_stats[1][epoch] = f1_list.std()\n",
    "    epochs_stats[2][epoch] = epoch_loss.mean()\n",
    "    \n",
    "    if epochs_stats[0][epoch] > f1_max:\n",
    "        torch.save(net.state_dict(), \"model.ebr\")\n",
    "        f1_max=epochs_stats[0][epoch]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Finished Training')\n",
    "stats_column_names = [\"F1\", \"F1 Standard Deviation\", \"Loss\"]\n",
    "train_stats = pd.DataFrame(epochs_stats, index=stats_column_names)\n",
    "train_stats.to_csv(\"Train_statistics.csv\", encoding=\"-utf8\", index=False)\n",
    "ind = np.where(epochs_stats[0]==epochs_stats[0].max())\n",
    "print(f\"Maximum F1: {epochs_stats[0].max()} standard deviation: {epochs_stats[1][ind]}, Minimum Loss: {epochs_stats[2].min()}\")\n",
    "df = pd.read_csv(\"Train_statistics.csv\")\n",
    "xs = []\n",
    "for i in range(100):\n",
    "    xs.append(i)\n",
    "array = df.to_numpy()\n",
    "t_student = 2.336242\n",
    "mult_factor = t_student/math.sqrt(20)\n",
    "err = []\n",
    "for i in range(len(array[1])):\n",
    "    err.append(array[1][i]*mult_factor)\n",
    "fig, ax1 = plt.subplots(figsize=(3.5, 3))\n",
    "ax1.set_xlabel(\"epoch\")\n",
    "ax1.set_ylabel(\"F1 Score\", color = \"blue\")\n",
    "ax1.plot(array[0], color=\"blue\")\n",
    "ax1.fill_between(x=xs, y1= (array[0]+err), y2=(array[0]-err), facecolor='blue',alpha=0.25,edgecolor='none')\n",
    "ax2 = ax1.twinx()\n",
    "ax2.set_ylabel(\"Loss\", color = \"red\")\n",
    "ax2.plot(array[2], color = \"red\")\n",
    "\n",
    "plt.savefig(\"f1.pdf\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "mcr = MulticlassRecall(num_classes=6, average=None)\n",
    "mccm = MulticlassConfusionMatrix(num_classes=6)\n",
    "\n",
    "net.eval()\n",
    "out = None\n",
    "lab = None\n",
    "f1_list = np.zeros(len(dl_test))\n",
    "running_loss = 0.0\n",
    "for i, data in enumerate(dl_test, 0):\n",
    "    inputs, labels = data\n",
    "    # forward + backward + optimize\n",
    "    outputs = net(inputs)\n",
    "\n",
    "\n",
    "    if out is None:\n",
    "        out = outputs.detach()\n",
    "    else:\n",
    "        out = np.vstack((out, outputs.detach()))\n",
    "\n",
    "    if lab is None:\n",
    "        lab = labels.detach()\n",
    "    else:\n",
    "        lab = np.hstack((lab, labels.detach()))\n",
    "    f1_list[i] = F1(outputs, labels).item()\n",
    "    if i % 10 == 9:    # print every 10 mini-batches\n",
    "        print(f\"[batch {i}, size: {dl_test.batch_size}] F1 score: {f1_list[i]}\")\n",
    "\n",
    "print(mcr(torch.Tensor(out), torch.Tensor(lab)))\n",
    "print(mccm(torch.Tensor(out), torch.Tensor(lab)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import matplotlib.pyplot as plt\n",
    "#import numpy as np\n",
    "#import pandas as pd\n",
    "#import seaborn as sb\n",
    "\n",
    "class_full_names = [\"Parassitic\", \"Wire Parallel Defect\", \"Wire Parallel Perfect\", \"Wire Tilted Defect\", \"Wire Tilted Perfect\", \"Null\",]\n",
    "class_names = [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\"]\n",
    "\n",
    "confusion_matrix = mccm(torch.Tensor(out), torch.Tensor(lab)).numpy()# np.array([[ 34,   2,   6,   0,   1,   1],\n",
    "                            #[  0,  11,  17,   0,   1,   2],\n",
    "                            #[  0,   5, 567,   1,   4,  14],\n",
    "                            #[  0,   1,   2,   4,   7,   2],\n",
    "                            #[  0,   1,   9,   2, 248,   5],\n",
    "                            #[  1,   4,  18,   2,   5, 129]], dtype=\"float\")\n",
    "norm_vector = np.linalg.norm(confusion_matrix, ord=1, axis=1)\n",
    "norm_vector = norm_vector.reshape(-1, 1)\n",
    "perc_matrix = np.round((confusion_matrix * 100 / norm_vector), 1)\n",
    "dataframe = pd.DataFrame(perc_matrix, index=class_names, columns=class_names)\n",
    "\n",
    "plt.figure(figsize=(3.5, 3))\n",
    " \n",
    "# Create heatmap\n",
    "sb.heatmap(dataframe, annot=True, cmap=\"rocket_r\", vmin = 0, vmax = 100)\n",
    "plt.title(\"Confusion Matrix\"), plt.tight_layout()\n",
    " \n",
    "plt.ylabel(\"True Class\"), \n",
    "plt.xlabel(\"Predicted Class\")\n",
    "plt.savefig(\"confusion_matrix.pdf\", bbox_inches=\"tight\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py37",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
